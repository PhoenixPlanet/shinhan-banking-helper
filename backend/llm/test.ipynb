{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class ClassifyResult(BaseModel):\n",
    "    term: str = Field(description=\"분류할 용어\")\n",
    "    is_financial: bool = Field(description=\"금융 용어 여부\")\n",
    "\n",
    "    \n",
    "class ClassifyBatchResult(BaseModel):\n",
    "    results: List[ClassifyResult] = Field(description=\"분류 결과 리스트\")\n",
    "\n",
    "\n",
    "class LLMClassifier:\n",
    "    def __init__(self, api_key, model_name):\n",
    "        if not api_key or not model_name:\n",
    "            raise ValueError(\"api_key or model_name is required\")\n",
    "        \n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.llm = ChatGoogleGenerativeAI(\n",
    "            model=model_name,\n",
    "            api_key=api_key,\n",
    "            temperature=0.1\n",
    "        ).with_structured_output(ClassifyResult)\n",
    "        \n",
    "        self.batch_llm = ChatGoogleGenerativeAI(\n",
    "            model=model_name,\n",
    "            api_key=api_key,\n",
    "            temperature=0.1\n",
    "        ).with_structured_output(ClassifyBatchResult)\n",
    "        \n",
    "        # 시스템 프롬프트 정의\n",
    "        self.system_prompt = \"\"\"당신은 금융 용어 분류 전문가입니다. \n",
    "주어진 단어나 구문이 금융/경제 관련 용어인지 아닌지를 판단해야 합니다.\n",
    "여기서 말하는 금융 용어란, 사용자가 은행 웹페이지를 사용하면서 어려움을 느껴 해설을 봐야겠다고 판단되는 용어를 의미합니다.\n",
    "\n",
    "각 용어에 대해 다음 JSON 형식으로 응답하세요:\n",
    "{res_format}\n",
    "\"\"\"\n",
    "\n",
    "        self.res_format_one = \"\"\"\n",
    "{\n",
    "    \"term\": \"대상 단어/구문\",\n",
    "    \"is_financial\": true/false,\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "        self.res_format_batch = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"term\": \"대상 단어/구문\",\n",
    "        \"is_financial\": true/false,\n",
    "    },\n",
    "    {\n",
    "        \"term\": \"대상 단어/구문\",\n",
    "        \"is_financial\": true/false,\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "        # 단일 용어 분류 프롬프트트\n",
    "        self.classify_prompt = ChatPromptTemplate([\n",
    "            (\"system\", self.system_prompt),\n",
    "            (\"human\", \"다음 단어/구문이 금융 용어인지 분류해주세요: {target_term}\")\n",
    "        ])\n",
    "        \n",
    "        # 여러 용어 배치 분류 프롬프트\n",
    "        self.batch_prompt = ChatPromptTemplate([\n",
    "            (\"system\", self.system_prompt),\n",
    "            (\"human\", \"다음 단어/구문들이 금융 용어인지 분류해주세요: {target_terms}\")\n",
    "        ])\n",
    "\n",
    "    def classify_term(self, term: str) -> Dict[Any, Any] | None:\n",
    "        try:\n",
    "            messages = self.classify_prompt.invoke({\"target_term\": term, \"res_format\": self.res_format_one})\n",
    "            response = self.llm.invoke(messages)\n",
    "            \n",
    "            if (isinstance(response, BaseModel)):\n",
    "                response = response.model_dump()\n",
    "            \n",
    "            if (not self._validate_response(response) or response['term'] != term):\n",
    "                return None\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"error: \", e)\n",
    "            return None\n",
    "        \n",
    "    def classify_terms_batch(self, terms: List[str]) -> List[Dict[Any, Any]] | None:\n",
    "        if not terms:\n",
    "            return None\n",
    "        \n",
    "        if len(terms) == 1:\n",
    "            result = self.classify_term(terms[0])\n",
    "            return [result] if result is not None else None\n",
    "        \n",
    "        terms_text = \", \".join(terms)\n",
    "        messages = self.batch_prompt.invoke({\"target_terms\": terms_text, \"res_format\": self.res_format_batch})\n",
    "    \n",
    "        response = self.batch_llm.invoke(messages)\n",
    "        if (isinstance(response, BaseModel)):\n",
    "            response = response.model_dump()\n",
    "            if ('results' in response):\n",
    "                response = response['results']\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        result_dict = {}\n",
    "        for res in response:\n",
    "            if (self._validate_response(res)):\n",
    "                result_dict[res['term']] = res['is_financial']\n",
    "            \n",
    "        results = []\n",
    "        for term in terms:\n",
    "            if (term in result_dict):\n",
    "                results.append({\n",
    "                    'term': term,\n",
    "                    'is_financial': result_dict[term]\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    'term': term,\n",
    "                    'is_financial': False\n",
    "                })\n",
    "                \n",
    "        return results\n",
    "        \n",
    "    def _validate_response(self, response: Dict[Any, Any]) -> bool:\n",
    "        if ('term' not in response or 'is_financial' not in response):\n",
    "            return False\n",
    "        \n",
    "        if (type(response['is_financial']) != bool):\n",
    "            return False\n",
    "        \n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62c0e75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'term': '안녕', 'is_financial': False}, {'term': '사과', 'is_financial': False}, {'term': 'ETF', 'is_financial': True}]\n"
     ]
    }
   ],
   "source": [
    "model = LLMClassifier(\"AIzaSyDsnbguduKB7AmxGCJ9vOXlyicINTNl3Jg\", \"gemini-2.5-flash\")\n",
    "\n",
    "print(model.classify_terms_batch([\"안녕\", \"사과\", \"ETF\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a45b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
